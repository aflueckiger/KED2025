{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 2 - Example Solution\n",
    "### Alex Fl√ºckiger\n",
    "### Seminar: The ABC of Computational Text Analysis\n",
    "### University of Lucerne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the play `Romeo and Juliet` from Project Gutenberg with `wget`. Steps:\n",
    "1. Open a shell \n",
    "2. Run `wget https://www.gutenberg.org/ebooks/1513.txt.utf-8`\n",
    "\n",
    "Make sure that the downloaded file is in the same folder as the code below. Otherwise, you need to adapt the file path in the code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'tragedy', 'of', 'romeo', 'and', 'juliet', 'by', 'william', 'shakespeare', 'contents']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('and', 736), ('the', 688), ('i', 659), ('to', 544), ('a', 488)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "infile = Path(\"1513.txt.utf-8\")\n",
    "text = infile.read_text()\n",
    "\n",
    "# replace the header with metainformation\n",
    "text = re.sub(r\"The Project Gutenberg.*START OF THE PROJECT GUTENBERG EBOOK ROMEO AND JULIET \\*\\*\\*\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "# replace footer with terms and conditions\n",
    "text = re.sub(r\"\\*\\*\\* END OF THE PROJECT GUTENBERG.*\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "# lowercase all text\n",
    "text = text.lower()\n",
    "\n",
    "### Bonus ###\n",
    "#  join lines, keep paragraphs\n",
    "def join_lines_keep_paragraphs(text):\n",
    "    # Split the text into paragraphs\n",
    "    paragraphs = text.split('\\n\\n')  # Assuming paragraphs are separated by two newlines\n",
    "\n",
    "    # Join lines within each paragraph\n",
    "    paragraphs = [' '.join(paragraph.split('\\n')) for paragraph in paragraphs]\n",
    "\n",
    "    # Join the paragraphs back together\n",
    "    joined_text = '\\n\\n'.join(paragraphs)\n",
    "\n",
    "    return joined_text\n",
    "\n",
    "text = join_lines_keep_paragraphs(text)\n",
    "### End of Bonus ###\n",
    "\n",
    "# write to file to check cleaned version\n",
    "outfile = Path(\"romeo_julia_cleaned.txt\")\n",
    "with outfile.open(\"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "# extract alphanumeric words without punctuation\n",
    "words = re.findall(r\"\\w+\", text)\n",
    "\n",
    "print(words[:10])\n",
    "\n",
    "# count words\n",
    "vocab = Counter(words)\n",
    "\n",
    "# write to file, one word and its frequency per line\n",
    "outfile = Path(\"romeo_julia_vocab_frq.tsv\")\n",
    "with outfile.open(\"w\") as f:\n",
    "    for word, frq in vocab.most_common():\n",
    "        line = f\"{word}\\t{frq}\\n\"\n",
    "        f.write(line)\n",
    "\n",
    "vocab.most_common(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the most frequent words are hard to interpret as they lack semantic meaning (so-called stopwords)\n",
    "- `Romeo` gets mentioned more often than `Juliet`\n",
    "- The `Capulet` family gets mentioned more often than `Montague`\n",
    "- `love` is among the highest ranking nouns and corresponds with the underlying theme of the novel\n",
    "- the adjective `good` is used more often than `bad` which might indicate a positive sentiment\n",
    "\n",
    "\n",
    "The word distribution is highly skewed and follows the [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law).\n",
    "It states that the frequency of a word is inversely proportional to its rank. This means that the most frequent word occurs twice as often as the second most frequent word, three times as often as the third most frequent word, and so on. This law is often used to identify stopwords, as they are the most frequent words in a text.\n",
    "\n",
    "If you skip the first few dozen words, however, you will usually see keywords that hints at the most important protagonists, themes and the general plot of a book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6 (main, Nov 14 2023, 09:36:21) [GCC 13.2.1 20230801]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2225c0e19c3f0c13ccd5f798c9a69d34844d1ef8ef2cd78fdeb33c1579f2ce2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
