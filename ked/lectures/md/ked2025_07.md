---
title: The ABC of Computational Text Analysis
subtitle: "#7 Working with (your own) Data"
author: "Alex Fl√ºckiger"
institute: "Faculty of Humanities and Social Sciences<br>University of Lucerne" 
date: "10 April 2025"
lang: en-US
---

## Recap last lecture

-   introducing Python üêç

-   learning programming concepts & syntax

    -   data types, loops, indexing, functions...

-   working with VS Code Editor

::: notes
-   praktische Anwendung von "trocken" eingef√ºhrten Elementen letztes Mal
-   Kern: Wie werden Daten repr√§sentiert und ver√§ndert in Python
    -   Variablen haben Datentypen
    -   Funktionen: wenn man die gleichen Arbeitschritte durchf√ºhren will.
        -   Abstraktion: ich muss mich gar nicht mehr um den genauen Inhalt dieser Funktion k√ºmmern
-   VS Code mit Jupyter Notebooks
:::

## Outline

-   learn about available data sources üóûÔ∏è
-   analyze and justify your own data
    -   convert `.pdf` into `.txt` üîÑ
    -   count words in Python üßÆ

::: notes
-   zweiteilige Sitzung
    -   Wo finde ich geeignete Datenquellen?
    -   Wie kann ich mit Python Text aus eigenen Daten extrahieren?
-   interessannte Datasets f√ºr die Sozialwissenschaften
    -   es gibt allerdings nicht viele
    -   zumeist eigene Daten pr√§parieren
-   eigene Textdaten nutzen inkl. Konversion gebr√§uchlicher Formaten
-   Arbeiten mit Textdaten in Python
:::

# Data sources {data-background-image="../images/text_data_mining.jpg"}

## What data sources are there?

-   broadly social
    -   newspapers + magazines
    -   websites + social media
    -   reports by NGOs/GOs
-   scientific articles
-   economic
    -   business plans/reports
    -   contracts
    -   patents

üëâ basically, any textual documents...

::: notes
-   Wir sind eine digitale Gesellschaft, die auf Schriftlichem aufbaut
    -   unheimliche Vielfalt an Dokumenten, alles neue digital
-   Textkollektion ist bereits vorhanden im Gegensatz zu Survey
    -   given data statt created data
    -   Datenaufbereitung n√∂tig
    -   Datenbereinigungen sind n√∂tig
-   hier nur einen Bruchteil vorgestellt, soll als Inspiration dienen
    -   Zeit reicht nicht, um auf alle Quellen einzugehen

[Image Credits](https://www.copyrightuser.org/understand/exceptions/text-data-mining/)
:::

## How does the data look like?

### Any text is data, yet some formats are more suitable

1.  datasets like `.csv` or `.tsv` ü•∞
2.  plain text like `.txt` üôÇ
3.  text in other formats like `.pdf` üò¨

::: notes
-   Am liebsten Datens√§tze

    -   sch√∂n strukturiert in Zeilen und Spalten mit Metainformationen
    -   Unterschied tsv csv
    -   direktes √ñffnen in Spreadsheet Programm oder Python

-   txt ohne Metainformation, aber bereit f√ºr Analyse

-   PDF braucht Extraktionsschritt

    -   anfangs Seminar angeschaut wir PDF in Texteditoren aussehen

-   manchmal steckt in Metainformation in Dateinamen (z.B Jahr)
:::

## Some great (historical) datasets

### Datasets in `.csv` ready off-the-shelf

-   [1 August speeches by Swiss Federal Councilors](https://www.republik.ch/2019/08/01/anleitung-fuer-die-perfekte-ansprache-zum-1-august)
    -   provided via [course repo](https://github.com/aflueckiger/KED2025/blob/main/ked/materials/data/dataset_speeches_federal_council_2019.csv), converted from [PDFs](https://www.admin.ch/gov/de/start/dokumentation/reden/ansprachen-zum-nationalfeiertag.html)
-   [Human Rights Reports by various NGOs](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IAH8OY)
-   [United Nations General Debate Corpus](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/0TJX8Y)
-   [Corpus of Resolutions: UN Security Council](https://zenodo.org/records/11212056)
-   [Inaugural Speeches by US Presidents](https://www.kaggle.com/datasets/adhok93/presidentialaddress)
-   [NewsWire](https://huggingface.co/datasets/dell-research-harvard/newswire)
    -   2.7M US news articles, 1878-1977

<br>

üòì There are still not many.

::: notes
-   sehr wenige standardisierte Datasets
    -   nicht wie bei Survey-Forschung (ESS), numerischer Daten aus Politik und √ñkonomie
-   Auswahl, die ich pers√∂nlich spannend finde
:::

## Dedicated search engines for datasets

### Use case: Search for existing datasets

-   [Harvard Dataverse](https://dataverse.harvard.edu/)
    -   open scientific data repository
-   [Google Dataset Search](https://datasetsearch.research.google.com)
    -   Google for datasets basically

<br>

üëâ search for a topic followed by `corpus`, `text collection` or `text as data`

::: notes
-   fortschrittliche Wissenschaft ver√∂ffentlicht nicht nur Papers, sondern auch Daten und Code
-   computergest√ºtzte Textanalyse ist aber immer noch Nische
-   Suchmaschinen f√ºr Datens√§tze
    -   nicht nur Text
    -   allerlei Datens√§tze, prim√§r aus Wissenschaft
-   Thema + Trigger-W√∂rter die auf Text hinweisen
:::

## Search techniques üîç {data-background="var(--green)"}

Make your (Google) web search more efficient by using dedicated [operators](https://support.google.com/websearch/answer/2466433?hl=en). Examples:

-   `"computational social science"`
-   `site:nytimes.com`
-   `nature OR environment`

::: notes
-   spezifischere Suche, weniger, aber genauere Ergebnisse
-   Quotes f√ºr W√∂rter, die zusammen geh√∂ren
-   Summe von W√∂rter haben evtl andere Bedeutung
-   Boolean Search - OR / AND
:::

## [Swissdox](https://swissdox.linguistik.uzh.ch/): A game changer

### Assemble a news dataset and download as `.tsv`

::::: columns
::: {.column width="50%"}
-   over 250 Swiss [newspapers](https://liri.linguistik.uzh.ch/wiki/langtech/swissdox/core/source)
-   historical and updated daily
-   needs registration (free)
:::

::: {.column width="50%"}
![](../images/swissdox.png)
:::
:::::

::: notes
-   Plattform von UZH
-   Medienberichte eine der spannendsten Quellen f√ºr Analyse sozialer Ph√§nomene
-   Perspektiven:
    -   L√§ngsschnitt (historisch) und Querschnittdaten (Verlage)
    -   Schweizer Illustrierte seit 1911
    -   NZZ seit 1994, Tages-Anzeiger 1995
-   Analyse von einem solchen Datensatz zu Wokeness n√§chste Woche
    -   kurze Demo
:::

## More publishers

-   [Nexis Uni](http://www.nexisuni.com/)
    -   international newspaper, business + legal reports
    -   licensed by the university
-   [Project Gutenberg](https://www.gutenberg.org/) and [HathiTrust](https://www.hathitrust.org/datasets)
    -   massive collection of books
    -   open, HathiTrust requires agreement
-   [Internet Archive](https://archive.org/)
    -   way-back-machine for web
    -   find "lost" web content

üëâ check out other resources licensed by [ZHB](https://www.zhbluzern.ch/recherche/e-medien)

::: notes
-   Nexis √§hnlich Swissdox, aber international
-   Projekt Gutenberg
    -   B√ºcher mit abgelaufenem Copyright (\>70 Jahre)
    -   Download als txt
    -   Wieso Literatur? ‚Äì\> Repr√§sentation von Zeitgeist
    -   genderspezifische Sprache, Verweise Natur/Umwelt
    -   relevant f√ºr Assignment
-   Internet Archive
    -   way-back-machine with snapshots
    -   check how the internet evolved overtime
:::

## Interesting sources as PDFs

### Any organization of your interest üëç

-   [Party Programmes across Europe](https://visuals.manifesto-project.wzb.eu/mpdb-shiny/cmp_dashboard_dataset/)
    -   covers over 1000 parties from 1920 until today in over 50 countries
-   [Swiss voting booklets](https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html)
    -   from 1977 until today
-   [Swissvotes](https://swissvotes.ch)
    -   collection of resources on Swiss public votings
-   [Curia Vista](https://www.parlament.ch/de/ratsbetrieb/suche-curia-vista)
    -   Swiss parliamentary debates
-   [Nestl√© Annual Reports](https://www.nestle.com/csv/performance/downloads)
-   [University of Zurich Annual Reports](https://www.archiv.uzh.ch/de/editionen/jahresberichte.html)

::: notes
-   Quellen meist Politik, Medien oder Firmen/Organisation
-   Jahresberichte UZH seit 1913, durch Studierende entdeckt
    -   grossartige Quelle f√ºr Wandel der Institution Universit√§t
:::

## Scraping PDFs from websites

### Use case: [Swiss voting booklets](https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html)

-   `wget` to download any files from the internet

``` bash
# get a single file
wget EXACT_URL

# get all linked pdf from a single webpage
wget --recursive --accept pdf -nH --cut-dirs=5 \
--ignore-case --wait 1 --level 1 --directory-prefix=data \
https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html

# --accept FORMAT_OF_YOUR_INTEREST
# --directory-prefix YOUR_OUTPUT_DIRECTORY
```

::: notes
-   Download Einzeldokument mit wget
    -   in Ubuntu/Terminal nicht Python
-   Wie aber Download automatisieren f√ºr viele Dokumente?
    -   Vorteil: schneller systematischer Download & Dokumentation von Quellen
    -   Startpunkt f√ºr Crawler, der automatisch alle Links durchsucht
-   kurze Demo in Finder mit Console-Split-Screen
    -   Rechtsklick f√ºr Linkadresse
    -   Haupt-URL angeben, wo PDF verlinkt sind
    -   nicht auf alle Argumente eingehen
-   Scraping von Blogs/Social-Media m√∂glich √ºber Python
    -   nicht Teil von Seminar
    -   anbieten f√ºr Scraping-Hilfe
:::

# Data is no free lunch üò•

::: notes
-   Daten sind delikate Angelegenheit

    -   Eigentum

    -   Bias

    -   Formate

-   im Folgenden, diese drei Dinge ansprechen
:::

## Data is property üö´

### ... and has rights too

-   copyrights may further limit access to high quality data
-   check the rights before processing data

![](../images/copyright.png){width="70%"}

::: notes
-   Zugang zu Daten nicht immer einfach
    -   Datenbereitstellung oftmals Teil von Gesch√§ftsmodell
        -   dann restriktiv
-   Copyright/Lizenz regelt Nutzung
-   Creative Commons
    -   Beispiel: Wikipedia
    -   nur Attribuierung n√∂tig
-   oftmals ist Verwendung nicht geregelt
    -   nutzt Graubereich f√ºr akademischen Rahmen
    -   Faustregel: was f√ºr √ñffentlichkeit bestimmt ist, kann analysiert werden
:::

## Imperfect data: A tail of bias

-   noise in text

    -   non-content (e.g. table of content), inconsistent spelling

-   archive holes

    -   lost or uncollected data

-   selective corpus curation

    -   supposition that key-word(s) captures topic

-   social bias

    -   view from somewhere, stereotypes

<br>

üëâ think about the data and mitigate issues

::: notes
-   non-content elements
    -   Metadaten, repetitive Kopfzeilen etc.
-   fehlende, selektive & verzerrte Daten
-   sozialer Kontext
    -   z.B. Budgetk√ºrzung oder Neuausrichtung --\> Wegfall von Thema
    -   Sicht von weissen M√§nnern auf Thema
:::

## . [A world for humans ...<br>... and a jungle of file formats.]{style="color:#0c0c0c;"} {data-background-image="../images/file_types.jpg"}

<!-- https://www.studio-24-7.com/file-formats-and-their-uses-explained/ -->

::: notes
-   extrem viele File-Typen
-   m√ºhsam, aber es gibt einfache Tools f√ºr Umwandlung
:::

## PDF: Digitized or digital?

### Two flavors of `.pdf` documents

::::: columns
::: {.column width="50%"}
![Digitalized PDF made from a scanned page](../../lectures/images/pdf_scan.png)
:::

::: {.column width="50%"}
![Native PDF converted from digital document (e.g., docx)](../../lectures/images/pdf_digital.png)
:::
:::::

::: notes
-   PDF ist Publikationsstandard
    -   aber zwei Varianten: digitale PDF vs Scan
-   Unterschied: in manchen kann man nicht Suchen
:::

## Optical Character Recognition (OCR)

::::: columns
::: {.column width="50%"}
-   OCR \~ convert images/scans into text
    -   may support handwriting + Fraktur texts
-   conversion steps
    -   convert to b/w image
    -   run OCR model
    -   correct spelling issues
:::

::: {.column width="50%"}
![Steps when performing OCR](../../lectures/images/ocr.png)
:::
:::::

## Common conversions

### Your text is of a particular type

::::: columns
::: {.column width="50%"}
‚¨áÔ∏è

digital native documents <br>`.pdf`, `.docx`, `.html`<br>

‚¨áÔ∏è

extract text without formatting
:::

::: {.column width="50%"}
‚¨áÔ∏è

scans of (old) documents <br>`.pdf`, `.jpg`, `.png`<br>

‚¨áÔ∏è

Optical Character Recognition (OCR)
:::
:::::

<br>

**machine-readable formats:** `.txt` or `.csv` ‚úÖ

::: notes
-   nach der Pause Schritte anschauen zur Umwandlung von digitalen PDF
    -   Scans nicht mehr Teil von Programm
    -   Nutzen und Ertrag nicht im Verh√§ltnis, Begriff OCR kennen
:::

## What data are you interested in?

### Think about your mini-project

::::: columns
::: {.column width="50%"}
-   present in last lecture
-   analyze any collection of text documents
    -   compare historically
    -   compare between actors
-   form groups of 2-3 people
-   requirements
    -   apply quantitative measures on multiple documents
    -   interpret and present results in class
    -   share executable script
:::

::: {.column width="50%"}
![Illustration of text analysis generated by Image Creator from Microsoft Copilot](../images/illustration_of_text_analysis.jpg)
:::
:::::

::: notes
-   paar Organisatorische Dinge vor der Pause
-   wir werden noch mehr Python Methoden anschauen, wichtig ist aber die Datenquelle
-   Je nach Datenquelle, Aufbereitung unterschiedlich aufwendig
:::

## Assignment #2 ‚úçÔ∏è

-   get/submit via OLAT
    -   starting tomorrow
    -   deadline: 19 April 2025, 23:59
-   discuss issues on OLAT forum

::: notes
-   √úbung: W√∂rter z√§hlen aus Buch von Projekt Gutenberg
-   Bash + Python
-   nicht bis zum Schluss warten
-   **Pause** (wichtig, damit genug Zeit bleibt f√ºr Coding)
:::

## Let's start [coding](https://github.com/aflueckiger/KED2025/blob/main/ked/materials/code/ked2025_07.ipynb) ‚ú®

## In-class: Exercises I {data-background="var(--blue)"}

1.  Make sure that your local copy of the Github repository KED2025 is up-to-date with `git pull`.
2.  Use `wget` to download *cogito* and its predecessor *uniluAKTUELL* issues (PDF files) from the [UniLu website](https://www.unilu.ch/magazin/service/pdf-und-archiv/#section=c67079). Start with downloading one issue first and then try to automatize the process to download all the listed issued using arguments for the `wget` command.
3.  Convert the *cogito* and *uniluAKTUELL* PDF files into TXT files. You can use the code given for native, digital PDFs (no OCR needed). Try with a single issue first and then write a loop to batch process all of them.
4.  What is the University of Lucerne talking about in its issues? Use the commands of the previous lectures to count the vocabulary.
5.  Do the same as in 4.), yet analyze the vocabulary of *cogito* and *uniluAKTUELL* issues separately. Does the language and topics differ between the two magazines?

# Questions? {.white-text data-background-image="../images/paint-anna-kolosyuk-unsplash.jpg"}