---
title: The ABC of Computational Text Analysis
subtitle: "#9 Ethics and the Evolution of NLP"
author: "Alex Fl√ºckiger"
institute: "Faculty of Humanities and Social Sciences<br>University of Lucerne" 
date: "25 April 2025"
lang: en-US
---

## Recap last lecture

-   perform first real-world (data) analysis üìä
    -   analyse discourse on wokeness in Swiss media
-   reminder: [share mini-project idea](https://docs.google.com/spreadsheets/d/1e91Eaj9U-9sNV1p3o7djPgrAR_mixWr_0GNrp6j37kQ/edit#gid=0) by 1 May

::: notes
-   assignment werde ich heute und morgen korrigieren
:::

## Outline

-   ethics is everywhere üôà üôâüôä
    -   ... and your responsibility
-   understand the development of modern NLP üöÄ
    -   ... or how to put words into computers

::: notes
-   heute ein Sprung, der √ºber praktischen Teil von Seminar hinausgeht
    -   Mix aus Ethik und Entwicklung aktueller NLP
    -   moderne NLP leistungsf√§higer als je zuvor, aber mit Problemen
-   AI ist Werkzeug, erstmal weder gut noch schlecht
    -   Vergleich I: Motor f√ºr Krankenwagen oder Panzer (Verteidigung/Angriff).
    -   Vergleich II: Internet f√ºr Wikipedia oder f√ºr Kinderpornographie
    -   Es sind wir Menschen, die die Technologie kontrollieren
-   Die Frage ist
    -   Wer profitiert genau von was? Wer verliert dabei?
:::

# **Ethics** is more than an academic subject.<br>It **is everywhere**.

# Apply for a job at a big company üéì üìÑ üè¢

# ü´µ {data-background-image="../images/cv.png"}

::: notes
-   Ethik ist nicht nur abstrakt und geh√∂rt nicht nur in Philosophie
    -   nicht Begriff ist wichtig, sondern Denkart
    -   nachdenken √ºber Ausgangslage + Konsequenzen
-   Anekdoten aus eigenem Bewerbungsprozess
    -   als Bewerber
    -   f√ºr Jobs, die Tools zur automatischen CV-Verarbeitung machen
:::

# Does your CV pass the automatic pre-filtering? <br> üî¥ üü¢

::: notes
-   automatische Vorselektion Bewerbungen
-   Aus welchen Gr√ºnden vorselektiert oder eben auch nicht?
-   bestenfalls: naiv, schlechtensfalls: anti-liberal/diskriminierend
:::

# Your interview is recorded. üï∂Ô∏è ü•µ

## What personal traits are inferred automatically?

![Facial expressions as perceived by a model by [@Peterson2022]](../images/face_impressions.jpg){width="80%"}

::: notes
-   Smartness korreliert mit Alter und Haarfarbe
-   Trustworthyness korrelliert mit sonnengebr√§unter Haut
-   Doch was sagen √Ñusserlichkeiten tats√§chlich √ºber psychologische Eigenschaften aus?
    -   Viel Pseudowissenschaft, auch von Topuniversit√§ten
:::

## Don't worry about the future...

![The narrative of autonomous and evil-minded robots is an illusion.](images/terminator_robot.jpg)

## ...worry about the present {data-background="var(--red)"}

-   AI is persuasive in everyday life
    -   assessing risks and performances (credit, job, crime, terrorism etc.) [@Hofmann2024]
-   AI is extremely capable
    -   increasingly difficult where it fails
-   AI has data-driven bias
    -   systems are often evaluated poorly

::: notes
-   je mehr die Systeme k√∂nnen, desto mehr werden sie eingesetzt,
    -   desto unsichtbarer wird, was sie nicht k√∂nnen
-   Moderne AI lernt Muster aus Daten. Gilt auch f√ºr NLP.
    -   generalisiert "blind" oder eben genau so wie gelernt
-   Existierende Ungleichheit wird reproduziert, gar verst√§rkt durch Systematik
    -   Geschlecht, Ethnie, sozio√∂konomisch
-   Problematik ist Reichweite, Intransparenz, Systematik
    -   Menschen auch fallibel, aber mit gr√∂sser Variet√§t
    -   Dinge werden pl√∂tzlich entscheidbar, die vorher ad hoc waren
-   Anwendungen f√ºr tabellarische Daten, Text, Bild, Video
    -   self-driving cars (kid vs adult, walking vs wheel chair)
-   Entwicklung NLP und Ethik h√§ngen zusammen
    -   quasi: je leistungsf√§higer NLP, desto mehr Bias wird mitgelernt im aktuellen Paradigma
    -   besseres Verst√§ndnis = bessere Data Science
:::

# An (r)evolution of NLP

## From bag of words to embeddings

### Putting words into computers [@Smith2020; @Church2021; @Manning2022]

-   from **coarse+static** to **fine+contextual** meaning
-   how to measure similarity of words and documents?
-   from counting to learning representations

::: notes
-   Ein Sprung, wie diese Technologie gewachsen ist
-   Probleme
    -   Bank kann Kreditinstitut bedeuten, in anderem Satz Parkbank
    -   Haus und Geb√§ude sehr √§hnlich, aber nicht reflektiert in Oberfl√§chenform
:::

## Bag of words

-   word as arbitrary, discrete numbers
    -   `King = 1, Queen = 2, Man = 3, Woman = 4`
-   intrinsic meaning
-   how are these words similar?

![Vector-representations of words as discrete symbols [@Colyer2016]](../images/word2vec-one-hot.png)

::: notes
-   Vektorrepr√§sentation f√ºr ganzes Vokubular
-   jedes Wort ist anderes als jedes andere, in unvergleichbarer Weise
-   BoW lange Zeit Standard. Erg√§nzt durch zus√§tzliche Information wie POS
:::

## Representing a corpus

:::::: columns
:::: {.column width="50%"}
### A collection of documents

::: l-left-align
1.  `NLP is great. I love NLP.`

2.  `I understand NLP.`

3.  `NLP, NLP, NLP.`
:::
::::

::: {.column width="50%"}
### Document term matrix

|              | `NLP` | `I` | `is` | ***term***           |
|--------------|-------|-----|------|----------------------|
| **Doc 1**    | 2     | 1   | 1    | ...                  |
| **Doc 2**    | 1     | 1   | 0    | ...                  |
| **Doc 3**    | 3     | 0   | 0    | ...                  |
| ***Doc ID*** | ...   | ... | ...  | ***term frequency*** |
:::
::::::

::: notes
-   f√ºr den Computer m√ºssen Daten tabularisiert werden f√ºr weitere Verarbeitung
:::

## "I eat `___` tonight". {data-background="var(--blue)"}

::: notes
-   W√∂rter k√∂nnen aber auch anders definiert werden
    -   hier ein Gedankenexperiment mit einem L√ºckentext
-   Frage an Studis
:::

## "The pizza was `___`." {data-background="var(--blue)"}

## 

> You shall know a word by the company it keeps!
>
> @Firth1957

::: notes
-   kontextuelle Bedeutung statt intrinschische Definition
-   Saussure: Zeichen nur definiert durch andere Zeichen
-   relationale Bedeutung: Objekt ist definiert durch Kontext
-   linguistische Theorie blieb lange ohne technische Implementation
    -   man hat einfach W√∂rter gez√§hlt (intrinsische Definition)
:::

## Formalize the linguistic intuition

1.  mask words
2.  let the computer predict them using its context

::: notes
-   Diese kontextuelle Definition kann man sich zunutze machen
-   Neues Modell
:::

## Word embeddings

### word2vec [@Mikolov2013]

-   words as continuous vectors
    -   accounting for similarity between words
-   semantic similarity
    -   `King ‚Äì Man + Woman = Queen`
    -   `France / Paris = Switzerland / Bern`

::: l-multiple
![Single continuous vector per word [@Colyer2016]](../images/word_vectors.png)

![Words as points in a semantic space [@Colyer2016]](../images/word2vec-king-queen-vectors.png)

![Doing arithmetics with words <br>[@Colyer2016]](../images/word2vec-king-queen-composition.png)
:::

::: notes
-   Seit 2013 hat sich alles ver√§ndert
-   vector = list of numbers -\> point in Euclidean space
-   Idee: wenn Wort √§hnlich verwendet wird (d.h. bedeutungs√§hnlich ist), dann √§hnliche Position
-   √ºberraschende Eigenschaft
    -   Synonyme
    -   Analogien (mit W√∂rter rechnen)
-   alles noch globale Information. Ein Wort hat genau ein Vektor
    -   Was passiert mit mehrdeutigen W√∂rter (z.B. Bank)?
-   Frage wie diese Repr√§sentationen genau gelernt wir nach Pause
:::

## Contextualized word embeddings

### BERT [@Devlin2019]

-   recontextualize static word embedding
    -   different embeddings in different contexts
    -   accounting for ambiguity (e.g., `bank`)
-   acquire linguistic knowledge from loads of data
    -   mask random phrases diverse sentences

::: notes
-   alles l√§sst sich embedden (W√∂rter, S√§tze, Paragraphen, Dokumente)
:::

## From embeddings to generation

### Instead of masking, train the model to predict the next word

![Autocompletion on iPhone](images/iphone_autocomplete.jpg)

::: notes
-   predict next word (Google Search, iPhone --\> screenshot)
:::

# Predicting the next word <br> is more powerful than you think! üí™

## It is a generic problem solver

### Any task can be modeled as Text-to-Text

![[@Raffel2020]](../images/t5_tasks.png)

## Large Language Models (LLM) üí•

### ChatGPT most successful, yet not unique

-   scale up approach of predicting the next word
    -   bigger models and more data
-   optimize for dialogue instead of prose text
    -   instruction-tuning (summarize, translate, reason)
    -   Reinforcement Learning from Human Feedback (RLHF)

::: notes
-   ChatGPT ist bekanntester Vertreter (gibt mehr) und hat historische Vorl√§ufer
-   Was hat sich ge√§ndert?
    -   Skalierung, Instruktionen, Automatisierung √ºber Reinforcement
-   RLHF
    -   Wenn man einmal ein gutes Modell hat, kann man verschiedene Outputs generieren lassen und Menschen bewerten lassen
    -   Anderes Modell entwickeln, das menschliche Bewertungen automatisiert
    -   Loop
-   √∂ffentliche Plattform f√ºhrt zu sehr vielen weiteren Daten
-   **Pause**
:::

# Modern NLP is propelled by data

::: notes
-   Sprung zur√ºck zu den Implikationen der Technologie
:::

## Associations in data

</br>

<p>[¬´]{style="font-family:Courier New,Courier,monospace"}[<code>\_\_\_</code>]{style="color:#e74c3c"} becomes a doctor.¬ª</p>

## Learning patterns from data

![Gender bias of the commonly used language model [BERT](https://pair.withgoogle.com/explorables/fill-in-the-blank) [@Devlin2019]](../images/bert_bias_doctor.png)

::: notes
-   BERT wird in Google Search gebraucht
-   Was ist das Problem? Gender Bias
:::

## Cultural associations in training data

![Gender bias of the commonly used language model [BERT](https://pair.withgoogle.com/explorables/fill-in-the-blank) [@Devlin2019]](../images/bert_bias_hobbies.png){width="70%"}

::: notes
-   Analyse umkehren: Nicht nach Pronomen fragen, sondern nach T√§tigkeiten
-   Model trained on Wikipedia and Books (not Reddit).
    -   gesellschaftlicher Fokus, so wie wir √ºber M√§nner und Frauen schreiben
:::

## Word embeddings are biased ...

### ... because ~~**our data** is~~ we are biased. [@Bender2021]

::: notes
-   Timnit Gebru (Google Ethics Lead) gefeuert f√ºr dieses Paper Ende 2020
-   Daten sind nicht besser als wir und Gesellschaft tr√§gt extreme Diskriminierungen mit sich
-   Mit Technologie wird Bias aber wieder systematisch in Gesellschaft zur√ºckgef√ºhrt
:::

## In-class: Exercises I {data-background="var(--blue)"}

1.  Open the following website in your browser: <https://pair.withgoogle.com/explorables/fill-in-the-blank/>
2.  Read the the article and play around with the interactive demo.
3.  What works surprisingly well? What looks flawed by societal bias? Where do you see limits of large language models?

# Modern AI = DL

## How does deep learning model look like?

![Simplified illustration of a neural network. Arrows are weights and bullets are (intermediate) states.](../images/neural_network.png)

::: notes
-   Ausgangslage sind Input-Output-Paare
    -   z.B. Satz ‚Äì\> positiv/neutral/negativ
-   Modell wird supervisiert gelernt um die Beziehung zwischen Input/Output zu lernen
-   Wie kann das Modell lernen?
:::

## How does deep learning work?

::: {#first-part}
### Deep learning [works](https://thinc.ai/docs/backprop101) like a huge bureaucracy

1.  **start** with **random** prediction
2.  **blame** units for contributing to **wrong predictions**
3.  **adjust** units based on the accounted blame
4.  **repeat** the cycle
:::

. . .

ü§ì train with **gradient descent**, a series of **small steps** taken **to minimize an error function**

## Current state of deep learning

### Extremely powerful but ... [@Bengio2021]

-   great at **learning patterns**, yet reasoning in its infancy
-   requires tons of data due to inefficient learning
-   generalizes poorly

::: notes
-   out of domain (schwarze vs weisse Menschen, anderes Textgenre)
-   da hat sich auch in den letzten Jahren nichts an dieser Grundlage ver√§ndert
:::

## Limitations of data-driven deep learning

<br>

::: {style="font-family:Courier New,Courier,monospace"}
"This sentence contains [37]{style="color:#3498db"} characters."<br /> "Dieser Satz enth√§lt [32]{style="color:#e74c3c"} Buchstaben."<br />
:::

<br />

. . .

![](../images/chatgpt_sentence_length.png){heigth="6cm"}

::: notes
-   ohne Trainingsdaten aktuell nicht zu l√∂sen
-   Auch ohne √úbersetzen funktionierts nicht. Modell hat keine Ahnung √ºber Anzahl Zeichen.
:::

## Biased data with practical implications

![Gender bias in [Google Translate](https://translate.google.com/?sl=en&tl=de&text=Your%20flatmate%20is%20smart.%0AYour%20flatmate%20is%20beautiful.%0A%0AThe%20engineer%20gets%20a%20promotion.%0AThe%20child%20carer%20goes%20to%20the%20zoo%20with%20the%20kids.%0AThe%20child%20carer%20gets%20a%20promotion.%0A%0A&op=translate)](../images/google_translate_bias.png){width="40%"}

::: notes
-   Stereotypen stecken auch in Produkten
-   Bilder oder Websites werden dadurch m√∂glicherweise schlechter gefunden
:::

## 

> Raw data is an oxymoron.
>
> @Gitelman2013

::: notes
-   Was sind Daten?
    -   Daten sind kein Abbild der Welt, nichts nat√ºrliches.
-   Analog zu Romanos: Massenmedien sind nicht die Welt
    -   Daten sind auch nicht die Welt
-   Daten liegen nicht einfach herum, sondern gemacht
-   Die Frage was Daten genau sind hat mit Realismus/Konstruktivismus-Debatte zu tun
    -   Konstruktivmus heisst nur, Fragen zu stellen, wieso die Dinge sind, wie sie ausschauen
:::

## Fair is a fad

-   companies also engage in fair AI to avoid regulation
-   **Fair** and **good** ‚Äì **but to whom?** [@Kalluri2020]
-   lacking democratic legitimacy

::: notes
-   Fair kann ziemlich vieles bedeuten, solange man es selbst definieren kann
    -   demokratische Legitimit√§t fehlt f√ºr all diese Systeme
-   looking beyond data
    -   invading privacy
    -   economic monopolies
    -   (unpaid) AI-trainers and click-workers
    -   environmental costs
:::

## 

> Don‚Äôt ask if artificial intelligence is good or fair, ask how it shifts power.
>
> @Kalluri2020

## Algorithmic managment of labour force

![Text generation may be used to communicate difficult decisions strategically](../images/chatgpt_headcount_reduction.png)

::: notes
-   Akkordarbeit und bei ungen√ºgender Leistung automatische Entlassung?
-   In Amazon Logistikzentren kommt auto-management zum Einsatz
-   sozial wahrscheinlich als perfide, unmoralische Kommunikation aufgefasst
:::

## Data represents real life. {data-background="var(--green)"}

Don't be a fool. Be wise, think twice.

## Additional resources

-   deepen your understanding of modern LLMs with

    -   [this video](https://www.youtube.com/watch?v=wjZofJX0v4M)

    -   [this animated explainer](https://ig.ft.com/generative-ai/)

# Questions? {.white-text data-background-image="../images/paint-anna-kolosyuk-unsplash.jpg"}

## References {.scrollable}