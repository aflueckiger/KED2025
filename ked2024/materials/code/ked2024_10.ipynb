{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<section id=\"title-slide\">\n",
    "  <h1 class=\"title\">The ABC of Computational Text Analysis</h1>\n",
    "  <h2 class=\"subtitle\">#10: NLP with Python</h2>\n",
    "  <p class=\"author\">Alex Fl√ºckiger</p><p class=\"date\">02/16 May 2024</p>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Update the course material\n",
    "1. Navigate to the course folde using `cd` in your command line\n",
    "2. Update the files with `git pull`\n",
    "3. If `git pull` doesn't work due to file conflicts, run `git restore .` first\n",
    "\n",
    "## Getting started \n",
    "1. Open VS Code\n",
    "2. Windows: Make sure that you are connected to WSL (green-badge in left-lower corner)\n",
    "3. Open the `KED2024` folder via the menu: `File` > `Open Folder`\n",
    "4. Navigate to `KED2024/ked2024/materials/code/KED2024_10.ipynb` and open with double-click\n",
    "5. Run the code with `Run all` via the top menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview analysis\n",
    "\n",
    "- get linguistic information from text\n",
    "- explore differences between two corpora \n",
    "    - using politcial party programmes\n",
    "- visualize term frequency over time\n",
    "  - using 1 August speeches by Swiss Federal Councillors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Do Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modules\n",
    "#### Standing of the shoulders of giants\n",
    "- [spaCy](https://spacy.io/usage/spacy-101): use or build state-of-the-art NLP pipeline\n",
    "- [textaCy](https://textacy.readthedocs.io): do high-level analysis, extends spaCy\n",
    "- [pandas](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html): analyze tabular data \n",
    "- [plotnine](https://plotnine.readthedocs.io): visualize anything (*ggplot for Python*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing modules\n",
    "\n",
    "various ways of importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard import\n",
    "import textacy\n",
    "import spacy\n",
    "\n",
    "# import with a short name\n",
    "import pandas as pd\n",
    "import scattertext as st\n",
    "\n",
    "# import all specific/all objects from a module\n",
    "from pathlib import Path\n",
    "from plotnine import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic NLP\n",
    "Process a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# example text (to read from a file see below)\n",
    "text = \"Apple's CEO Tim Cook is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "# load the English language model\n",
    "en = textacy.load_spacy_lang(\"en_core_web_sm\")\n",
    "\n",
    "# process document (tokenizing, tagging, parsing, recognizing named entities)\n",
    "doc = textacy.make_spacy_doc(text, lang=en)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linguistic features\n",
    "Features per token and their linguistic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# visualize dependencies\n",
    "spacy.displacy.render(doc, style=\"dep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# iterate over tokens of a document\n",
    "for token in doc:\n",
    "    print(\n",
    "        token.text,\n",
    "        \"-->\",\n",
    "        token.lemma_,\n",
    "        token.pos_,\n",
    "        token.dep_,\n",
    "        token.shape_,\n",
    "        token.is_alpha,\n",
    "        token.is_stop, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# visualize named entities\n",
    "spacy.displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# iterate over named entities of a document\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} --> {ent.label_} ({spacy.explain(ent.label_)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternatively, read from a single txt file\n",
    "f_text = \"../data/swiss_party_programmes/txt/sp_programmes/1920_parteiprogramm_d.txt\"\n",
    "text = Path(f_text).read_text()\n",
    "\n",
    "print(text[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Steps to create a corpus\n",
    "\n",
    "How to make a corpus from many text files?\n",
    "\n",
    "1. list all files of a folder \n",
    "2. read text from each file\n",
    "3. parse metadata from file name\n",
    "4. return each document sequentially\n",
    "\n",
    "&rarr; wrap all this in a function `get_texts_and_metadata()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_texts_and_metadata(dir_texts):\n",
    "    \"\"\"\n",
    "    Sequentially stream all documents from a given folder, including metadata.\n",
    "    \"\"\"\n",
    "    p = Path(dir_texts)  # set base directory\n",
    "\n",
    "    # iterate over all documents in base directory recursively\n",
    "    for fname in p.glob(\"**/*.txt\"):\n",
    "\n",
    "        print(\"Parsing file:\", fname.name)\n",
    "\n",
    "        text = Path(fname).read_text()\n",
    "        # join lines as there are hard line-breaks\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        # further modify the text here if needed\n",
    "\n",
    "        # parse year from filename and set a metadata\n",
    "        # example: 1920_parteiprogramm_d.txt --> year=1920\n",
    "        try:\n",
    "            year = int(fname.name.split(\"_\")[0])\n",
    "        except ValueError:\n",
    "            print(\"WARNING: Parsing meta data has failed:\", fname.name)\n",
    "            continue\n",
    "\n",
    "        # add more metadata here if needed\n",
    "        metadata = {\"fname\": fname.name, \"year\": year}\n",
    "\n",
    "        # return documents one after another (sequentially)\n",
    "        yield (text, metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create a corpus from TXT\n",
    "Process documents and create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# stream texts from a given folder\n",
    "dir_texts = \"../data/swiss_party_programmes/txt/sp_programmes/\"\n",
    "texts_and_metadata = get_texts_and_metadata(dir_texts)\n",
    "\n",
    "# load German language model\n",
    "de = textacy.load_spacy_lang(\"de_core_news_sm\")\n",
    "\n",
    "# create corpus from processed documents\n",
    "corpus = textacy.Corpus(de, data=texts_and_metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic corpus statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"# documents:\", corpus.n_docs)\n",
    "print(\"# sentences:\", corpus.n_sents)\n",
    "print(\"# tokens:\", corpus.n_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Export word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get lowercased and filtered corpus vocabulary\n",
    "vocab = corpus.word_counts(\n",
    "    by=\"lemma_\", # text for un-lemmatized words\n",
    "    weighting=\"count\", # freq for relative frequency\n",
    "    filter_stops=True,\n",
    "    filter_punct=True,\n",
    "    filter_nums=True,\n",
    ")\n",
    "\n",
    "# sort vocabulary by descending frequency\n",
    "vocab_sorted = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# write to file, one word and its frequency per line\n",
    "fname = \"../analysis/vocab_frq.txt\"\n",
    "with open(fname, \"w\") as f:\n",
    "    for word, frq in vocab_sorted:\n",
    "        line = f\"{word}\\t{frq}\\n\"\n",
    "        f.write(line)\n",
    "\n",
    "vocab_sorted[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with subcorpus\n",
    "\n",
    "Interested in a group of documents only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# select the first document in corpus\n",
    "first_doc = corpus[0]\n",
    "print(first_doc._.meta)\n",
    "print(first_doc.text[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# function to filter by metadata, e.g. publication year after 1900\n",
    "def filter_func(doc):\n",
    "    return doc._.meta.get(\"year\") > 1900\n",
    "\n",
    "\n",
    "# create new corpus after applying filter function\n",
    "subcorpus = textacy.corpus.Corpus(de, data=corpus.get(filter_func))\n",
    "\n",
    "subcorpus.n_docs, corpus.n_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key Word in Context (KWIC)\n",
    "\n",
    "Show words in their original context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over documents and print matches\n",
    "# you can use regular expressions as keyword\n",
    "for doc in corpus:\n",
    "    results = textacy.extract.kwic.keyword_in_context(\n",
    "        doc.text, keyword=\"(Ausland|Inland)\", ignore_case=True, window_width=50\n",
    "    )\n",
    "    for match in results:\n",
    "        print(f\"{match[0]}  {match[1]}  {match[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Export results to TXT File\n",
    "\n",
    "collect any information and write to file\n",
    "- particular terms or linguistic constructions\n",
    "- Named Entities (NE)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# collect information\n",
    "for doc in corpus:\n",
    "    for sent in doc.sents:\n",
    "        if \"Armut\" in sent.text:\n",
    "            # match contains the sentence where the term occurs, preceded by the filename (tab-separated)\n",
    "            match = f\"{doc._.meta['fname']}\\t{sent.text}\"\n",
    "            results.append(match)\n",
    "\n",
    "# write information to file\n",
    "fname = \"../analysis/sents_poverty.txt\"\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"\\n\".join(results))\n",
    "\n",
    "print(results[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Export corpus as CSV Dataset\n",
    "We have created a corpus containing all party programmes. Now, let's save it as csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# merge dictionary with metadata and dictionary with actual text for each document in the corpus\n",
    "data = [doc._.meta | {\"text\": doc.text} for doc in corpus]\n",
    "\n",
    "# export corpus as csv\n",
    "f_csv = \"../data/swiss_party_programmes/corpus_party_programmes.csv\"\n",
    "textacy.io.csv.write_csv(data, f_csv, fieldnames=data[0].keys())\n",
    "\n",
    "# check the data of the first party programm\n",
    "data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# In-class: Exercises I\n",
    "\n",
    "1. Make sure that your local copy of the Github repository KED2024 is up-to-date with `git pull`. You can find the relevant material as follows:\n",
    "- notebook `/KED2024/ked2024/materials/code/KED2024_10.ipynb`\n",
    "- party programmes `/KED2024/ked2024/materials/data/swiss_party_programmes/txt`\n",
    "\n",
    "2. Open the notebook in VS Code. *@Windows people*: Make sure that you are connected to WSL Ubuntu (check green badge).\n",
    "\n",
    "3. Run all the code in the notebook by clicking `Run All`.\n",
    "\n",
    "4. Process another English sentence with spaCy instead of the one mentioning Apple.\n",
    "\n",
    "5. Load the German language model and process a German sentence. Display the linguist information and check the difference between the lemma and the form as it occurs in the text.\n",
    "\n",
    "6. Play around with the code as it is a good way to learn. Modify one thing, run the code, and see if the output matches your expectations. Start easy and then get increasingly brave until the code breaks. Fix the issue and try again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Explore corpus of 1 August speeches interactively\n",
    "\n",
    "![Example Scattertext](../analysis/viz_party_differences.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What the graph shows\n",
    "- speeches by the Swiss Federal Councilors on 1 August\n",
    "- visualize the difference between speakers of *Social Democratic Party of Switzerland* (SP) and other parties\n",
    "- interpretation\n",
    "  -  top right: terms used by all\n",
    "  -  top left: terms primarily used by SP\n",
    "  -  lower right: terms primarily used by other parties\n",
    " \n",
    "[Explore interactively in your browser](https://aflueckiger.github.io/KED2024/materials/analysis/viz_party_differences.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scattertext\n",
    "\n",
    "- how does language differ by two groups\n",
    "    - organization, person, gender, time etc.\n",
    "- interactive exploring\n",
    "- find discriminative terms\n",
    "- scoring function *rank-frequency*\n",
    "    - normalized by number of terms `[0,1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load CSV File\n",
    "\n",
    "Load a dataset of 1 August speeches by Swiss federal councillors (received from [Republik, original article](https://www.republik.ch/2019/08/01/anleitung-fuer-die-perfekte-ansprache-zum-1-august))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# read dataset from csv file\n",
    "f_csv = \"../data/dataset_speeches_federal_council_2019.csv\"\n",
    "df = pd.read_csv(f_csv)\n",
    "\n",
    "# make new column containing all relevant metadata\n",
    "df[\"descripton\"] = df[[\"Redner\", \"Partei\", \"Jahr\"]].astype(str).agg(\", \".join, axis=1)\n",
    "\n",
    "# filter out non-german texts or very short texts\n",
    "df_sub = df[(df[\"Sprache\"] == \"de\") & (df[\"Text\"].str.len() > 10)]\n",
    "\n",
    "# sneak peek of dataset\n",
    "df_sub.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create scattertext plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "censor_tags = set(['CARD']) # tags to ignore in corpus, e.g. numbers\n",
    "\n",
    "# stop words to ignore in corpus\n",
    "de_stopwords = spacy.lang.de.stop_words.STOP_WORDS # default stop words\n",
    "custom_stopwords = set(['[', ']', '%', \"*\"])\n",
    "de_stopwords = de_stopwords.union(custom_stopwords) # extend with custom stop words\n",
    "\n",
    "# create corpus from dataframe\n",
    "# lemmatized and lowercased terms, no stopwords, no numbers\n",
    "corpus_speeches = st.CorpusFromPandas(df_sub, # dataset\n",
    "                             category_col='Partei', # index differences by ...\n",
    "                             text_col='Text', \n",
    "                             nlp=de, # German model\n",
    "                             feats_from_spacy_doc=st.FeatsFromSpacyDoc(tag_types_to_censor=censor_tags, use_lemmas=True),\n",
    "                             ).build().get_stoplisted_unigram_corpus(de_stopwords)\n",
    "# produce visualization (interactive html)\n",
    "html = st.produce_scattertext_explorer(corpus_speeches,\n",
    "            category='SP', # set attribute to divide corpus into two parts\n",
    "            category_name='SP',\n",
    "            not_category_name='other parties',\n",
    "            metadata=df_sub['descripton'],\n",
    "            width_in_pixels=1000,\n",
    "            minimum_term_frequency=5, # drop terms occurring less than 5 times\n",
    "            save_svg_button=True,                          \n",
    ")\n",
    "\n",
    "# write visualization to html file\n",
    "fname = \"../analysis/viz_party_differences.html\"\n",
    "open(fname, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plot term frequencies over time\n",
    "\n",
    "![Example](../analysis/rel_term_frq_nation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create corpus from CSV\n",
    "\n",
    "How to make a corpus from a dataset in `.csv`-format?\n",
    "\n",
    "&rarr; define a new function `get_texts_from_csv`, similar to `get_texts_and_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_texts_from_csv(f_csv, text_column):\n",
    "    \"\"\"\n",
    "    Read dataset from a csv file and sequentially stream the rows,\n",
    "    including metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    # read dataframe\n",
    "    df = pd.read_csv(f_csv)\n",
    "\n",
    "    # keep only documents that have text\n",
    "    filtered_df = df[df[text_column].notnull()]\n",
    "\n",
    "    # iterate over rows in dataframe\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "\n",
    "        # get text and join lines (remove hard line-breaks)\n",
    "        text = row[text_column].replace(\"\\n\", \" \")\n",
    "\n",
    "        # use all columns as metadata, except the column with the actual text\n",
    "        metadata = row.to_dict()\n",
    "        del metadata[text_column]\n",
    "\n",
    "        yield (text, metadata)\n",
    "\n",
    "\n",
    "f_csv = \"../data/dataset_speeches_federal_council_2019.csv\"\n",
    "texts = get_texts_from_csv(f_csv, text_column=\"Text\")\n",
    "\n",
    "corpus_speeches = textacy.Corpus(de, data=texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create a group-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# define how groups are formed and what terms should be included\n",
    "# here, we get a list of lemmatized words (incl. stop words) and labels (=years) for each document\n",
    "tokenized_docs, labels = textacy.io.unzip(\n",
    "    (\n",
    "        textacy.extract.utils.terms_to_strings(\n",
    "            textacy.extract.words(doc, filter_stops=False), by=\"lemma\"\n",
    "        ),\n",
    "        doc._.meta[\"Jahr\"],\n",
    "    )\n",
    "    for doc in corpus_speeches\n",
    ")\n",
    "\n",
    "# define how to count\n",
    "# here relative term frequency\n",
    "vectorizer = textacy.representations.vectorizers.GroupVectorizer(\n",
    "    tf_type=\"linear\",  # absolute term frequency\n",
    "    dl_type=\"linear\",  # normalized by document length\n",
    "    vocabulary_grps=range(1950, 2019),\n",
    ")  # limit to years from 1950 to 2019\n",
    "\n",
    "# create group-term-matrix with with frequency counts\n",
    "grp_term_matrix = vectorizer.fit_transform(tokenized_docs, labels)\n",
    "\n",
    "# create dataframe from matrix\n",
    "df_terms = pd.DataFrame(\n",
    "    grp_term_matrix.toarray(), index=vectorizer.grps_list, columns=vectorizer.terms_list\n",
    ")\n",
    "df_terms[\"year\"] = df_terms.index\n",
    "\n",
    "# change shape of dataframe\n",
    "df_tidy = df_terms.melt(id_vars=\"year\", var_name=\"term\", value_name=\"frequency\")\n",
    "df_tidy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot frequencies over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# filter the dataset for the following terms\n",
    "terms = [\"Volk\", \"Schweiz\", \"Nation\"]\n",
    "df_terms = df_tidy[df_tidy[\"term\"].isin(terms)]\n",
    "\n",
    "# plot the relative frequency for the terms above\n",
    "(\n",
    "    ggplot(df_terms, aes(x=\"year\", y=\"frequency\", color=\"term\"))\n",
    "    + geom_point()  # show individual points\n",
    "    + stat_smooth(\n",
    "        method=\"lowess\", span=0.15, se=False\n",
    "    )  # overlay points with a smoothed line\n",
    "    + theme_classic()\n",
    ")  # make the plot look nicer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Save Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check some other terms\n",
    "terms = [\"Solidarit√§t\", \"Kultur\", \"Wert\"]\n",
    "\n",
    "df_terms = df_tidy[df_tidy[\"term\"].isin(terms)]\n",
    "\n",
    "p = (\n",
    "    ggplot(df_terms, aes(\"year\", \"frequency\", color=\"term\"))\n",
    "    + geom_point(alpha=0.5, stroke=0)\n",
    "    + stat_smooth(method=\"lowess\", span=0.10, se=False)\n",
    "    + theme_classic()\n",
    ")\n",
    "\n",
    "# save as png\n",
    "fname = \"../analysis/rel_term_frq_culture.png\"\n",
    "p.save(filename=fname, dpi=150, verbose=False)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Number of documents per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "docs_per_year = (\n",
    "    df_sub.groupby(\"Jahr\")\n",
    "    .agg({\"Text\": \"count\"})\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Text\": \"count\"})\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(docs_per_year, aes(x=\"Jahr\", y=\"count\"))\n",
    "    + geom_line(color=\"darkblue\")\n",
    "    + labs(title=\"Number of Speeches per Year\", x=\"Year\", y=\"absolute frequency\")\n",
    "    + scale_y_continuous(breaks=range(0, 20, 2), expand=(0, 1))\n",
    "    + scale_x_continuous(breaks=range(1930, 2021, 10), expand=(0, 10))\n",
    "    + theme_classic()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Status</th>\n",
       "      <th>Vollst√§ndigkeit</th>\n",
       "      <th>Redner</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>Funktion</th>\n",
       "      <th>Partei</th>\n",
       "      <th>Partei-Original</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Bemerkung</th>\n",
       "      <th>Sprache</th>\n",
       "      <th>Originalsprache</th>\n",
       "      <th>Ort</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Anrede</th>\n",
       "      <th>Text</th>\n",
       "      <th>Originaltext</th>\n",
       "      <th>Quelle</th>\n",
       "      <th>descripton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Alain Berset</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sehr geehrte Damen und Herren</td>\n",
       "      <td>Wir leben in der Schweiz in Frieden und Wohlst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.admin.ch/gov/de/start/dokumentatio...</td>\n",
       "      <td>Alain Berset, SP, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Alain Berset</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>Lokal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de, fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Euschels, Belfaux, R√ºtli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wir leben in der Schweiz in Frieden und Wohlst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.admin.ch/gov/de/start/dokumentatio...</td>\n",
       "      <td>Alain Berset, SP, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Alain Berset</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>Lokal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de, fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alp Oberer Euschels, Belfaux, R√ºtli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wir leben in der Schweiz in Frieden und Wohlst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.admin.ch/gov/de/start/dokumentatio...</td>\n",
       "      <td>Alain Berset, SP, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Doris Leuthard</td>\n",
       "      <td>f</td>\n",
       "      <td>BR</td>\n",
       "      <td>CVP</td>\n",
       "      <td>CVP</td>\n",
       "      <td>Lokal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Villmergen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liebe Mitb√ºrgerinnen und Mitb√ºrger</td>\n",
       "      <td>Ich bedanke mich f√ºr die Einladung zu Ihrer 1....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.admin.ch/gov/de/start/dokumentatio...</td>\n",
       "      <td>Doris Leuthard, CVP, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Guy Parmelin</td>\n",
       "      <td>m</td>\n",
       "      <td>BR</td>\n",
       "      <td>SVP</td>\n",
       "      <td>SVP</td>\n",
       "      <td>Lokal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¬´Armbrust und Hellebarde¬ª</td>\n",
       "      <td>Sehr geehrte Eidgenossen, Meine Damen und Herren</td>\n",
       "      <td>Eine 1.-August-Rede ist eine der heikelsten rh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.admin.ch/gov/de/start/dokumentatio...</td>\n",
       "      <td>Guy Parmelin, SVP, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1937</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Giuseppe Motta</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>CVP</td>\n",
       "      <td>SKVP</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>f√ºr Auslandschweizer</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meine Damen und Herren, liebe Landsleute,</td>\n",
       "      <td>Es ist nicht das erste Mal, dass ich die Freud...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NZZ vom 2. August 1937, Mittagsausgabe Nr. 139...</td>\n",
       "      <td>Giuseppe Motta, CVP, 1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1936</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Albert Meyer</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In republikanischer Schlichtheit und Einfachhe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NZZ vom 3. August 1936, Morgenausgabe Nr. 1825...</td>\n",
       "      <td>Albert Meyer, FDP, 1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1935</td>\n",
       "      <td>done</td>\n",
       "      <td>vollst√§ndig</td>\n",
       "      <td>Rudolf Minger</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>SVP</td>\n",
       "      <td>BGB</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>wurde Lokal gehalten</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berner, Eidgenossen!</td>\n",
       "      <td>¬´Als Demut weint und Hochmut lacht, da ward de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rudolf Minger spricht. Francke Verlag Bern, 1967</td>\n",
       "      <td>Rudolf Minger, SVP, 1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1934</td>\n",
       "      <td>fehlt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcel Pilet-Golaz</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcel Pilet-Golaz, FDP, 1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1933</td>\n",
       "      <td>fehlt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edmund Schulthess</td>\n",
       "      <td>m</td>\n",
       "      <td>BP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>FDP</td>\n",
       "      <td>BP-Rede</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edmund Schulthess, FDP, 1933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Jahr Status Vollst√§ndigkeit              Redner Geschlecht Funktion  \\\n",
       "0    2018   done     vollst√§ndig        Alain Berset          m       BP   \n",
       "1    2018   done     vollst√§ndig        Alain Berset          m       BP   \n",
       "2    2018   done     vollst√§ndig        Alain Berset          m       BP   \n",
       "3    2018   done     vollst√§ndig      Doris Leuthard          f       BR   \n",
       "4    2018   done     vollst√§ndig        Guy Parmelin          m       BR   \n",
       "..    ...    ...             ...                 ...        ...      ...   \n",
       "165  1937   done     vollst√§ndig      Giuseppe Motta          m       BP   \n",
       "166  1936   done     vollst√§ndig        Albert Meyer          m       BP   \n",
       "167  1935   done     vollst√§ndig       Rudolf Minger          m       BP   \n",
       "168  1934  fehlt             NaN  Marcel Pilet-Golaz          m       BP   \n",
       "169  1933  fehlt             NaN   Edmund Schulthess          m       BP   \n",
       "\n",
       "    Partei Partei-Original      Typ             Bemerkung Sprache  \\\n",
       "0       SP              SP  BP-Rede                   NaN      de   \n",
       "1       SP              SP    Lokal                   NaN  de, fr   \n",
       "2       SP              SP    Lokal                   NaN  de, fr   \n",
       "3      CVP             CVP    Lokal                   NaN      de   \n",
       "4      SVP             SVP    Lokal                   NaN      de   \n",
       "..     ...             ...      ...                   ...     ...   \n",
       "165    CVP            SKVP  BP-Rede  f√ºr Auslandschweizer      de   \n",
       "166    FDP             FDP  BP-Rede                   NaN      de   \n",
       "167    SVP             BGB  BP-Rede  wurde Lokal gehalten      de   \n",
       "168    FDP             FDP  BP-Rede                   NaN     NaN   \n",
       "169    FDP             FDP  BP-Rede                   NaN     NaN   \n",
       "\n",
       "    Originalsprache                                  Ort  \\\n",
       "0               NaN                                  NaN   \n",
       "1               NaN             Euschels, Belfaux, R√ºtli   \n",
       "2               NaN  Alp Oberer Euschels, Belfaux, R√ºtli   \n",
       "3               NaN                           Villmergen   \n",
       "4               NaN                                  NaN   \n",
       "..              ...                                  ...   \n",
       "165             NaN                                  NaN   \n",
       "166             NaN                                  NaN   \n",
       "167             NaN                                  NaN   \n",
       "168             NaN                                  NaN   \n",
       "169             NaN                                  NaN   \n",
       "\n",
       "                         Titel  \\\n",
       "0                          NaN   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4    ¬´Armbrust und Hellebarde¬ª   \n",
       "..                         ...   \n",
       "165                        NaN   \n",
       "166                        NaN   \n",
       "167                        NaN   \n",
       "168                        NaN   \n",
       "169                        NaN   \n",
       "\n",
       "                                               Anrede  \\\n",
       "0                       Sehr geehrte Damen und Herren   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                  Liebe Mitb√ºrgerinnen und Mitb√ºrger   \n",
       "4    Sehr geehrte Eidgenossen, Meine Damen und Herren   \n",
       "..                                                ...   \n",
       "165         Meine Damen und Herren, liebe Landsleute,   \n",
       "166                                               NaN   \n",
       "167                              Berner, Eidgenossen!   \n",
       "168                                               NaN   \n",
       "169                                               NaN   \n",
       "\n",
       "                                                  Text Originaltext  \\\n",
       "0    Wir leben in der Schweiz in Frieden und Wohlst...          NaN   \n",
       "1    Wir leben in der Schweiz in Frieden und Wohlst...          NaN   \n",
       "2    Wir leben in der Schweiz in Frieden und Wohlst...          NaN   \n",
       "3    Ich bedanke mich f√ºr die Einladung zu Ihrer 1....          NaN   \n",
       "4    Eine 1.-August-Rede ist eine der heikelsten rh...          NaN   \n",
       "..                                                 ...          ...   \n",
       "165  Es ist nicht das erste Mal, dass ich die Freud...          NaN   \n",
       "166  In republikanischer Schlichtheit und Einfachhe...          NaN   \n",
       "167  ¬´Als Demut weint und Hochmut lacht, da ward de...          NaN   \n",
       "168                                                NaN          NaN   \n",
       "169                                                NaN          NaN   \n",
       "\n",
       "                                                Quelle  \\\n",
       "0    https://www.admin.ch/gov/de/start/dokumentatio...   \n",
       "1    https://www.admin.ch/gov/de/start/dokumentatio...   \n",
       "2    https://www.admin.ch/gov/de/start/dokumentatio...   \n",
       "3    https://www.admin.ch/gov/de/start/dokumentatio...   \n",
       "4    https://www.admin.ch/gov/de/start/dokumentatio...   \n",
       "..                                                 ...   \n",
       "165  NZZ vom 2. August 1937, Mittagsausgabe Nr. 139...   \n",
       "166  NZZ vom 3. August 1936, Morgenausgabe Nr. 1825...   \n",
       "167   Rudolf Minger spricht. Francke Verlag Bern, 1967   \n",
       "168                                                NaN   \n",
       "169                                                NaN   \n",
       "\n",
       "                        descripton  \n",
       "0           Alain Berset, SP, 2018  \n",
       "1           Alain Berset, SP, 2018  \n",
       "2           Alain Berset, SP, 2018  \n",
       "3        Doris Leuthard, CVP, 2018  \n",
       "4          Guy Parmelin, SVP, 2018  \n",
       "..                             ...  \n",
       "165      Giuseppe Motta, CVP, 1937  \n",
       "166        Albert Meyer, FDP, 1936  \n",
       "167       Rudolf Minger, SVP, 1935  \n",
       "168  Marcel Pilet-Golaz, FDP, 1934  \n",
       "169   Edmund Schulthess, FDP, 1933  \n",
       "\n",
       "[170 rows x 19 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"new_column\"] = \"Your value for all rows in this column\"\n",
    "df_combined =  pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working on mini-project\n",
    "\n",
    "Ask questions, <br>\n",
    "I am ready to help!\n",
    "\n",
    "![Help!](../../lectures/images/help_frog.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "#### tutorials for spaCy\n",
    "\n",
    "- [official spaCy 101](https://spacy.io/usage/spacy-101)\n",
    "- [official online course spaCy](https://course.spacy.io/en/chapter1)\n",
    "- [Hitchhiker's Guide to NLP in spaCy](https://www.kaggle.com/nirant/hitchhiker-s-guide-to-nlp-in-spacy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "rise": {
   "enable_chalkboard": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2225c0e19c3f0c13ccd5f798c9a69d34844d1ef8ef2cd78fdeb33c1579f2ce2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
